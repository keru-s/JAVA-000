# 毕业总结

[TOC]



## 前言

转眼训练营就已经结束了，回想这一路中不断赶听课、赶作业，真是一段辛苦而又充实的旅途。秦老师给我梳理了整个 Java 的知识体系，让我对这一系列的知识点有了本质的认识，虽然很多细节没有认识，但是当我需要去深入时，老师给我梳理的体系就起到了很大的作用，让我能快速掌握很多的知识点。虽然整个训练营没有做出来什么项目，但是还是很幸运能成为 0 期学员，希望年后能找到一份好工作。

----

## JVM

Java 作为一门跨平台的语言，之所以能起到一处编译，处处运行的效果，是因为 JVM 的存在，JVM 的全程是 Java 虚拟机，通过在硬件和操作系统之上，模拟出一个虚拟的操作系统，从而使字节码能够在各个平台上执行同样的功能。

JVM 分为很多部分，其中最重要的有以下两个部分：

- 类加载
- Java 内存模型
- 垃圾回收

### 类加载

Java 作为一门面对对象的语言，程序员的最终产物就是一个个的类，要将编写的类文件，转换成程序运行时指令，就需要将字节码文件加载进 JVM 中，这样才能在运行时找到对应的程序执行逻辑。而将字节码文件加载进 JVM 中的流程就是类加载。类加载最重要的机制就是双亲委派机制，简单来说，就是 Java 一共有 3 种类加载器，每次加载类时，都会从最底部的类加载器逐级向上寻找，如果找到就返回，如果没找到，再重新交给下一层的类加载器来加载，直至找到合适的类加载器，将类加载进 JVM 中。

### Java 内存模型

JVM 定义了一个内存模型，规定了类和对象的存放区域，并根据内存模型来执行垃圾回收算法，从而实现自动回收内存。

Java 的内存模型简单来说将内存划分为了几个区域：

- 栈：为每个线程分配空间，每个线程栈中又有大量的方法调用按调用顺序堆叠，称之为栈帧，每个栈帧中保存的是方法的运行指令。
- 堆：堆是用于存放对象的空间，主要分为新生代和老年代。新生代又分为伊甸区和幸存者区。根据对象创建的特点（朝生夕死），将对象放置在不同的区域中，并根据不同的区域采用不同的垃圾回收算法。
- 非堆：存放一些 JVM 运行过程中的元数据。

### 垃圾回收

Java 诞生之初，就想要解决 C++ 存在的手动回收问题，因此 JVM 设计了大量的垃圾回收算法，根据堆中不同代的特点，可以使用不同的算法来进行垃圾回收。

#### 串行 GC

串行 GC 适用于单核的 client 端机器上，因为减少了线程间的切换，所以在内存较小的时候，也能起到较好的回收效果。

#### 并行 GC

并行 GC 使用了多线程进行 GC，因此相较于串行 GC， 回收的速度更快，适用于多核的 server 端机器上，然而如果需要回收的内存区域较大，那么会造成比较长的 GC 时间。

#### CMS

cms 相较于并行 GC，将整个 GC 回收过程拆分成了好几步，在 GC 的大多数时间里，允许与业务代码并行执行，减少了 GC 对业务的影响，但是仍然避免不了大内存回收时，STW 对业务的影响。

#### G1

G1 相较于 CMS，不仅将 GC 的过程拆分的更细致了，而且将内存区域从较大的新生代、老年代，变成非常多的小块区域，这样就可以对较小的区域使用整理复制的方式进行 GC，因此可以控制最大 STW 的时间，让 GC 对业务的影响变得更小。

#### 总结

1. GC 的进化史，就是一个不断细化的过程

   - 串行 GC 到并行 GC，是从一个线程到多个线程的进化
   - 并行 GC 到 CMS，是 GC 回收过程的细化。
   - CMS 到 G1，是 GC 回收区域的细化。

   通过对 GC 的细化，我们可以更为精准的把控 GC 的过程，从而让 GC 的时间更短，对系统的影响更小。这就类比于，我们把一个大事务，拆成多个小事务，一个大颗粒的线程锁控制，拆成多个小颗粒的线程锁控制一样。

2. GC 的进化史，也是从够用到好用的进化史。

   - 串行 GC 到并行 GC，是想办法提供 GC 速度，降低 STW 对业务影响的过程。
   - 并行 GC -> CMS -> G1，则开始着力去解决吞吐量，响应时延这些更影响业务和用户体验方面的问题。

### JDK 内置的命令行工具

JDK 内置了许多命令行工具，能让我们在生产环境通过命令行快速获取 JVM 的相关信息，常用的工具有以下几种：

- JPS：查看 Java 的进程和启动参数。
- jstat：查看 GC 情况
- jmap：内存工具，可以查看 JVM 中的内存信息
  - 查看 JVM 的内存配置信息和使用信息。
  - 打 dump
  - 查看占用内存最多的类的排序

----

## NIO

NIO 模型是从 BIO 发展而来的，最早的网络通信，是创建多个线程来监听网络请求，如果收到了网络请求，则进行处理，否则就处于阻塞状态，当访问量快速上升后，由于 CPU 的上下文切换需要时间，为请求创建大量的线程变得不太现实，因此需要更新通信模型，NIO 就是用少量的线程来管理网络请求的接收和处理，大大提高了程序可容纳的访问量。

### netty

netty 是一个网络通信框架，通过提供一套统一的API，将多种网络模型的复杂性封装在了框架之下，从而使程序员能够基于 Netty 快速地搭建属于自己的网络通信应用。通过 Netty 来实现 NIO 是非常简单且常见的事情。

### 网关

网关的分类

- 流量网关
- 业务网关

#### 流量网关

关注稳定和安全，性能好。常见的有：Nginx、Kong

主要功能：

- 全局性流控
- 日志统计
- 防止 SQL 注入
- 防止 Web 攻击
- 屏蔽工具扫描
- 黑白 IP 名单
- 证书/加解密处理

#### 业务网关

提供更好的服务，扩展性好，适合二次开发。常见的有：Spring Cloud Gateway、Zuul2

- 服务级别流控
- 服务降级与熔断
- 路由与负载均衡、灰度策略
- 服务过滤、聚合与发现
- 权限验证与用户等级策略
- 业务规则与参数校验
- 多级缓存策略

----

## 并发编程

并发编程之所以出现，是因为摩尔定律走到了瓶颈，人类很难提升单核的处理性能，因此通过将多核组合起来提升计算机的处理能力，拥有了多核，程序就可以同时运行多段处理逻辑，而非只能顺序地进行处理，为了充分利用多核性能，因此诞生了并发编程。

并发编程主要涉及到以下几个知识点：

- 多线程
- 线程池
- 并发包
- 集合类

----

## Spring 和 ORM 等框架

### Spring

Spring 框架用于管理对象、业务层级的一个框架，通过 Spring 定义好的一个个层次，我们只需在一个个小格子里编写代码，就能完成业务的需求。它的核心功能就是：依赖注入、面向切面编程。由于它的出现，改变了整个 Java 的 Web 编程模型，因此它成为了 Web 开发的事实标准.

后续它不断地与各种服务集成，然后又演进出了无需配置，开箱即用的 SpringBoot，Spring Boot 是基于 Spring 的，可以快速开发的脚手架，为了快速开发，它实现了两大核心功能。

1. 自动化配置：简化配置核心，基于 Configuration、EnableXX，Condition
2. spring-boot-starter（脚手架）:整合各种第三方类库，对工具进行协同处理。

在 SpringBoot 的基础上，对各种组件集成后整合出了微服务解决方案：Spring Cloud。

### ORM

ORM 框架是将关系数据库中的表映射到 Java 对象的一种框架，相较于原生的 JDBC，可以让研发人员更方便地进行 SQL 的编写，最常用的 ORM 框架有：Hibernate、MyBatis。

----

## MySQL 数据库和 SQL

MySQL 是关系型数据库，由于其开源且性能较好，逐步取代了 Oracle，成为了互联网开发中最常用的数据库。

在 MySQL 中，最重要的知识点有以下几个：

- 事务：事务和事务的隔离级别，对程序的运行效率和执行结果的正确性有很大的影响。
- 锁：要数据的正确性，就需要在各种粒度来加锁，常见的锁有：表锁、行锁、间隙锁。
- 日志：为了支持 MySQL 中的事务隔离级别，MySQL 通过记 log 来完成这件事。在 InnoDB 中，日志包括了 undo log 和 redo log。
- 索引优化

----

## 分库分表

### 为什么要做数据库拆分

业务飞速发展导致了数据规模的急速膨胀，单机数据库已经无法适应互联网业务的发展。

传统的将数据集中存储至单一数据节点的解决方案，在容量、性能、可用性和运维成本这三方面已经难于满足互联网的海量数据场景。我们在单库单表数据量超过一定容量水位的情况下，索引树层级增加，磁盘 IO 也很可能出现压力，会导致很多问题。

从性能方面来说，由于关系型数据库大多采用 B+树类型的索引，在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，进而导致查询性能的下降；同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈。

从可用性的方面来讲，服务化的无状态型，能够达到较小成本的随意扩容，这必然导致系统的最终压力都落在数据库之上。而单一的数据节点，或者简单的主从架构，已经越来越难以承担。从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。

### 从读写分离到数据库拆分

主从结构解决了高可用，读扩展，但是单机容量不变，单机写性能无法解决。

提升容量和写性能，有两种思路，一种是硬件思路，为机器加CPU、内存等，但是硬件的性能有尽头，更高性能的硬件往往花费不菲，第二种思路，同多核的思想一样，进行分布式，即，分库分表、分布式，这样，多个数据库就能作为数据分片的集群提供服务，能有效降低单个节点的写压力。提升整个系统的数据容量上限。

### 数据库扩展

数据的扩展有三个方向

- 数据复制：对全部数据进行复制，从而实现主从结构、备份和高可用。
- 垂直分库分表：按业务对数据分类，符合分布式服务化、微服务的趋势，缺点是：对业务有改动（需修改SQL），业务领域有边界和数量限制，不能无限扩大。
- 水平分库分表：对任意数据都有效，可以实现真正的分布式结构，支持任意扩容。

#### 垂直拆分

垂直拆分（**拆库**）：将一个数据库，拆分成多个提供不同业务数据处理能力的数据库。

> 例如拆分所有订单的数据和产品的数据，变成两个独立的库，这种方式对业务系统有极大的影响，因为数据结构本身发生了变化， SQL  和关联关系也必随之发生了改变。原来一个复杂  SQL直接把一批订单和相关的产品都查了出来，现在这个  SQL  不能用了，得改写  SQL  和程序。先查询订单库数据，拿到这批订单对应的所有产品  id ，再根据产品  id  集合去产品库查询所有的产品信息，最后再业务代码里进行组装。

垂直拆分（**拆表**）：如果单表数据量过大，还可能需要对单表进行拆分。

> 比如一个  200  列的订单主表，拆分成十几个子表：订单表、订单详情表、订单收件信息表、订
> 单支付表、订单产品快照表等等。这个对业务系统的影响有时候可能会大到跟新作一个系统差
> 不多。对于一个高并发的线上生产系统进行改造，就像是给心脑血管做手术，动的愈多，越核
> 心，出现大故障的风险越高。所以，我们一般情况下，尽量少用这种办法。

**优点：**

1. 单库 （单表） 变小，便于管理和维护
2. 对性能和容量有提升作用
3. 改造后，系统和数据复杂度降低
4. 可以作为微服务改造的基础

**缺点**：

1. 库变多，管理变复杂
2. 对业务系统有较强的侵入性
3. 改造过程复杂，容易出故障
4. 拆分到一定程度就无法继续拆分

#### 水平拆分

分为：分库、分表、分库+分表三类

按**主键分库分表**：水平拆分就是直接对数据进行分片，有分库和分表两个具体方式，但是都只是降低单个节点数据量，但不改变数据本身的结构。这样对业务系统本身的代码逻辑来说，就不需要做特别大的改动，甚至可以基于一些中间件做到透明。

> 比如把一个  10  亿条记录的订单单库单表（ orderDB  库  t_order  表）。我们按照用户  id  除以 32  取模，把单库拆分成  32  个库 orderDB_00..31 ；再按订单  id  除以  32  取模，每个库里再拆分成  32  个表 t_order_00..31 。这样一共是  1024  个子表，单个表的数据量就只是  10  万条了。一个查询如果能够直接路由到某个具体的字表，比如 orderDB05.t_order_10  ，那么查询效率就会高很多。

按**时间分库分表**：很多时候，我们的数据是有时间属性的，所以自然可以按照时间维度来拆分。比如当前数据表和历史数据表，甚至按季度，按月，按天来划分不同的表。这样我们按照时间维度来查询数据时，就可以直接定位到当前的这个子表。

**强制按条件指定**分库分表：比如配置好某些用户的数据进入单独的库表，其他数据默认处理。

**自定义方式**分库分表：指定某些条件的数据进入到某些库或表。

##### 分库还是分表，如何选择

一般情况下，如果数据本身的读写压力较大，磁盘  IO  已经成为瓶颈，那么分库比分表要好。分库将数据分散到不同的数据库实例，使用不同的磁盘，从而可以并行提升整个集群的并行数据处理能力。相反的情况下，可以尽量多考虑分表，降低单表的数据量，从而减少单表操作的时间，同时也能在单个数据库上使用并行操作多个表来增加处理能力。

#### 分库分表优缺点

**优点**：

1. 解决容量问题
2. 比垂直拆分对系统影响小
3. 部分提升性能和稳定性

**缺点**:

1. 集群规模大，管理复杂
2. 复杂 SQL 支持问题（业务侵入性、性能）
3. 数据迁移问题
4. 一致性问题

----

## RPC 和微服务

### RPC

#### 是什么

RPC是远程过程调用（Remote Procedure Call）的缩写形式。简单来说，就是“**像调用本地方法一样调用远程方法**”。

RPC的概念与技术早在1981年由Nelson提出。

1984年，Birrell和Nelson把其用于支持异构型分布式系统间的通讯。Birrell的RPC 模型引入存根进程( stub) 作为远程的本地代理，调用RPC运行时库来传输网络中的调用。Stub和RPC runtime屏蔽了网络调用所涉及的许多细节，特别是，参数的编码/译码及网络通讯是由stub和RPC runtime完成的，因此这一模式被各类RPC所采用。

#### 为什么

在 Spring 发明之前，一个 Java 项目中使用的接口实现都是通过直接引用来调用的。当业务变得复杂之后，需要对业务进行拆分，这个时候就出现了二方库，通过引入二方库来调用具体接口，但是这样就会暴露接口的具体实现，因为通过代码的反编译，我们很容易地知道接口的内部实现，而且，每次接口内部实现要进行变更，都需要所有引入二方库的服务进行版本升级。

后来有了网络，人们想要解决直接引用和二方库带来的问题，就像能不能通过一种基础措施，在不改变业务代码的情况下，将 new 一个接口实现，改成直接通过网络调用某个接口获取返回接口，这就是 RPC 的由来。

#### 常见的RPC技术

- JSON RPC, XML RPC，WebService(Axis2, CXF)
- Hessian, Thrift, Protocol Buffer, gRPC

#### 核心原理

核心是代理机制。

1. 本地代理存根: Stub。
2. 本地序列化反序列化
3. 网络通信
4. 远程序列化反序列化
5. 远程服务存根: Skeleton。通过传递过来的接口和方法，找到远程服务中的实现类。
6. 调用实际业务服务
7. 原路返回服务结果
8. 返回给本地调用方

### 微服务

微服务主要有四个要点：

1. 根据业务模块划分服务种类。 
2. 每个服务可以独立部署并且互相隔离。 
3. 通过轻量的 API 调用服务。
4. 服务需要保证良好的高可用性。

#### 微服务架构要解决的问题

微服务架构要达到三大要求：

- 高可用
- 高并发
- 高性能

要达到这三大要求，就需要解决以下这四个问题：

##### 一、客户端如何访问这么多的服务？

使用 API 网关对服务进行聚合，客户端通过访问 API 网关来获取相应的服务

##### 二、服务之间如何通信

服务之间的通信有两种解决方案：

1. 同步通信

   1. HTTP：Apache HTTP Client
   2. RPC：Dubbo、gRPC

2. 异步通信

   消息队列：kafka、Rabbit MQ、Rocket MQ

##### 三、多个服务要怎样管理（治理）

本质上就是要实现服务的注册与发现

- 基于客户端的服务注册与发现：Zookeeper
- 基于服务端的服务注册与发现：Eureka

##### 四、服务提供者宕机要如何应对

- 重试机制
- 服务熔断
- 服务降级
- 服务限流

----

## 分布式缓存

### 缓存的来龙去脉

#### 本地缓存

### 常用

- Guava
- Spring Cache 注解

### 缺点

1. 在多个集群环境同步。当集群规模增大，缓存需要读写很多分，占用大量内存。
2. 在JVM中长期占用内存，如果是堆内存，总是会影响GC。
3. 缓存数据的调度处理，需要各种线程进行异步处理，影响执行业务的线程，抢资源。

#### 远程缓存

为了解决本地缓存的缺点，就需要集中处理缓存，这就有了远程缓存。

#### 常用缓存中间件

- Redis：由Salvatore Sanfilippo写的key-value存储系统。Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。
- Memcached：以LiveJournal旗下Danga Interactive公司的Brad Fitzpatric为首开发的一款开源高性能，分布式内存对象缓存系统。

#### 内存网格

概念：支持分布式、一致性、多副本的缓存服务器；也可以作为 Jar 包，放在客户端使用；最厉害的地方在于，支持将 Java 中的大部分数据结构以分布式的方式实现。当通过内存网格创建一个Map实例后，在节点A调用 `Map::put(“A”,”A_DATA”)` 方法添加数据，节点B使用 `Map::get(“A”)` 可以获到值为`”A_DATA”` 的数据。

- Hazelcast
- Ignite

**缺点**

1. 如果缓存所在服务器失效，所有应用都无法使用缓存。
2. 多了一跳网络调用。

### 缓存策略

容量：所有资源有限。

- 缓存数据容量是必须要考虑的问题
- 思考系统的设计容量、使用容量、峰值，应该是我们做架构设计的一个常识

 过期策略：

- 按队列的策略：常用的是FIFO或LRU。
- 按固定时间过期
- 按业务时间加权：根据业务，可以将不同时间的数据缓存不同的小时数。比如变动少的日期数据缓存久一点，变动多的数据缓存时间少一点。

### 缓存三大常见问题

#### 缓存穿透

**定义**：大量并发查询不存在的KEY，导致都直接将压力透传到数据库。

这样就有可能被人利用，拼凑大量不存在的key，造成对数据库的 DDoS 攻击。

**解决办法**：

1. 缓存空值的KEY，这样第一次不存在也会被加载会记录，下次拿到有这个KEY。
2. Bloom 过滤或 RoaringBitmap 判断KEY是否存在。
3. 解耦：完全以缓存为准，使用 延迟异步加载 的策略2，这样就不会触发更新。

#### 缓存击穿

**定义**：某个KEY失效的时候，正好有大量并发请求访问这个KEY，这就会导致有大量线程对这个Key进行更新。

**解决办法**：

1. KEY的更新操作添加全局互斥锁。
2. 解耦：完全以缓存为准，使用 延迟异步加载 的策略2，这样就不会触发更新。

#### 缓存雪崩

**定义**：当某一时刻发生大规模的缓存失效的情况，会有大量的请求进来直接打到数据库，导致数据库压力过大升值宕机。

分析：一般来说，由于更新策略、或者数据热点、缓存服务宕机等原因，可能会导致缓存数据同一个时间点大规模不可用，或者都更新。所以，需要我们的更新策略要在时间上合适，数据要均匀分散，缓存服务器要多台高可用。

**解决办法**：

1. 更新策略在时间上做到比较均匀。
2. 使用的热数据尽量分散到不同的机器上。
3. 多台机器做主从复制或者多副本，实现高可用。
4. 实现熔断限流机制，对系统进行负载能力控制。

----

## 分布式消息队列

### 系统间通信方式

随着计算机的发展，我们可以在计算机中同时运行多个程序，这时我们就遇到一个问题，如果进行系统间的通信。

在早期，互联网还没发明之前，一台计算机内，**两个进程需要进行通信，常用的有这三种方式**：

1. 基于文件：两个进程对同一个文件进行读写，这样就可以进行通信。
2. 基于共享内存：指定一块内存，让两个进程都可以对该内存进行读写，其实就是基于文件的升级版，比基于文件的速度要快，但是断电会丢失。
3. 基于IPC（**进程间通信**）：IPC 是操作系统或者编程语言提供的一组接口，让程序可以通过调用接口来实现两个进程间的通信，进程间通信主要包括 管道, 系统IPC（包括 消息队列,信号, 共享内存), 套接字(SOCKET)。

后来诞生了互联网，基于互联网，系统间的通信方式有了升级：

1. 基于数据库：两个系统连接到同一个数据库上，通过对数据库进行 CRUD 来进行通信。
2. 基于Socket：是 IPC 的升级版，两个系统通过建立 Socket 连接，进行互相通信。
3. 基于RPC：RPC 相较 Socket 更近一步，通过封装，隐藏掉了连接的细节，让系统间的通信变得更加方便。

但是，每个模式都有自己的缺点：

- 文件: 明显不方便，不及时
- Socket：使用麻烦，多数情况下不如RPC
- 数据库：不实时，但是经常有人拿数据库来模拟消息队列
- RPC：调用关系复杂，同步处理，压力大的时候无法缓冲

基于此，我们期望有一种通信方式，具有以下的优点：

- 可以实现异步的消息通信
- 可以简化参与各方的复杂依赖关系
- 可以在请求量很大的时候，可以实现削峰填谷，降低系统的瞬时压力。
- 某些情况下能保障消息的可靠性，甚至顺序

为了满足以上的要求，就诞生了 MQ，即消息队列，它有很多称呼，包括：Message Queue、Messaging System、Message Middlewire。

MQ 的模式是：系统将需要沟通的信息交给 MQ，由 MQ 发往指定的系统。因此可以理解成快递业务，各个厂商之间，通过快递来运送原材料，最终制造出商品。

### 从队列到消息服务

可以说，MQ 是内存里的 Queue 的升级版，我们将内存里的 Queue 抽出来，做成一个可以独立部署，供多个系统调用的中间件，这就是 MQ 的雏形。通过这个雏形， MQ 抽象出了四个核心概念：

- Message：消息，用来传递信息的数据。
- Queue：队列，消息的载体。
- Producter：生产者：生产消息方
- Consumer：消费者：消费消息方，消费有两种方式：推、拉。推：MQ 实时推送给消费者，实时性好；拉：消费者轮询拉取消息，可以进行批量处理。

### 消息模式

#### 消息处理模式

有了 MQ 之后，接下来就需要考虑消费者如何消费消息了。根据 MQ 模型，最先想到的，当然就是一个生产者生产，一个消费者消费的模式，这种消息处理模式，被称为 点对点模式。但实际工作中，单单只有点对点模式是不够的，一份消息，有可能会有多个下游需要消费到，如果为每个下游都建立一个 MQ，费时费力不说，也大大增加了维护成本，与当初设计 MQ 来解耦的目的相违背，因此，我们发明了另一种处理方式，发布订阅模式，一个生产者将消息发布到 MQ 中，多个消费者按需订阅消息，这样就可以简单的实现一对多了。

所以，常见的消息处理模式有两种：

- 点对点：PTP，Point-To-Point
  对应于Queue
- 发布订阅：PubSub，Publish-Subscribe，
  对应于Topic

#### 消息处理的保障

有得必有失，消息的发送的效率和可靠性就是相互对立的，想要保证消息发送的效率，就必然会影响消息送达的可靠性，这与数据库的事务隔离级别是相似的。

为了平衡消息的发送的效率和可靠性，业界定义了三种 QoS（服务质量） （注意：这是消息语义的，不是业务语义的）：

- At most once(QoS 0)：至多一次，消息可能丢失但是不会重复发送。因此无需 ack 机制，速度最快。
- At least once(QoS 1)：至少一次，消息不会丢失，但是可能会重复。需要 ack 机制，速度一般。
- Exactly once(QoS 2)：精确一次，每条消息肯定会被传输一次且仅一次。在 ack 机制下，增加了消费位置的记录，通过这种方式来保证精确一次。速度最慢。

#### 事务性

MQ 是支持事务的，即可以保证一系列消息一起被消费掉，如果有其中一个消息出现异常，则该事务中的所有消息都会重新进行消费。

- 通过确认机制实现事务性；
- 可以被事务管理器管理，甚至可以支持XA

#### 消息有序性

同一个Topic或Queue的消息，MQ 能保障按顺序投递。
**注意**：如果做了消息分区，或者批量预取之类的操作，就无法保证全局的顺序了。

### 消息协议

决定了 MQ 的消费方式之后，我们还需要定义生产者和消费者跟 MQ 交互的协议，因为只有有了协议，才能保证在各种环境下都是能正常交互的。

当前常见的协议有以下几种：

- [STOMP](https://stomp.github.io/)：简单的面向文本的消息协议。通过文本格式来进行消息交互，类似于 JSON。
- JMS：Java Message Service，是 J2EE 定义的一套 Java 程序与 MQ 进行交互的接口，由各 MQ 来实现交互的具体细节，类似于JDBC。
- AMQP：高级消息协议，基于这一套协议，任意编程语言和任意 MQ 遵守这个协议可以实现异步通讯。RabbitMQ 就是基于该协议进行实现的。
- [MQTT](https://vernemq.com/intro/mqtt-primer/)：最开始是 MQ 遥感传输协议，但如今不是这种含义了。如今他代表的是一种发布订阅协议，适用于高延迟、低带宽、网络不稳定的环境。
- XMPP：XMPP基于XML，用于IM系统的开发。国内比较流行的XMPP服务器叫做Openfire。
- Open Messaging：阿里发起的一个 MQ 协议。

### MQ 发展史

由协议和技术的发展，产生了三代 MQ：

1. ActiveMQ/RabbitMQ：消息处理基于内存，速度快，但不进行持久化处理，处理有上限，无法进行堆积，会产生背压。
2. Kafka/RocketMQ：消息持久化在磁盘中，利用磁盘的有序性提高速度，可以保存消息，进行大量的消息堆积。
3. Apache Pulsar：将消息的处理和存储进行分离，可以针对业务情况，对处理节点或存储节点进行单独的扩容。